---
title: "LLM Pricing in February 2026: What Every Model Actually Costs"
description: "A complete comparison of LLM API pricing across OpenAI, Anthropic, Google, Meta, DeepSeek, and xAI. Input and output costs per million tokens, updated February 2026."
date: "2026-02-19"
author: "Kael Tiwari"
tags: ["pricing", "llm", "analysis"]
published: true
---

**TL;DR:** Cheapest usable model is Gemini 2.0 Flash at $0.10/M input. Best value is GPT-5 mini at $0.25/M. Most expensive is Grok-4 at $30/M — 120x more than GPT-5 mini for questionable upside. Full table with all 16 models below.

---

If you're building on top of LLMs right now, you're probably spending more than you need to. Pricing has changed so fast over the past year that most teams are running on outdated assumptions.

Here's what every major model actually costs as of February 2026, with the context that matters for choosing between them.

## The full pricing table

All prices are per million tokens.

| Model | Provider | Input | Output | Notes |
|-------|----------|-------|--------|-------|
| GPT-5.2 | OpenAI | $1.75 | $14.00 | Flagship, best overall quality |
| GPT-5 mini | OpenAI | $0.25 | $2.00 | Best price/performance ratio |
| GPT-4.1 | OpenAI | $2.00 | $8.00 | Still widely deployed |
| GPT-4.1 nano | OpenAI | $0.10 | $0.40 | Cheapest OpenAI option |
| o4-mini | OpenAI | $1.10 | $4.40 | Reasoning model |
| Claude Opus 4 | Anthropic | $15.00 | $75.00 | Premium tier, complex reasoning |
| Claude Sonnet 4 | Anthropic | $3.00 | $15.00 | Workhorse model |
| Claude Haiku 3.5 | Anthropic | $0.80 | $4.00 | Fast + cheap |
| Gemini 2.5 Flash | Google | $0.30 | $2.50 | Strong on long context |
| Gemini 2.0 Flash | Google | $0.10 | $0.40 | Budget tier |
| Llama 4 Maverick | Meta (via API) | $0.27 | $0.85 | Open-weight, self-hostable |
| DeepSeek V3.1 | DeepSeek | $0.60 | $1.70 | Chinese lab, surprisingly strong |
| Grok-4 | xAI | $30.00 | $150.00 | Most expensive model on market |
| Grok-4-fast | xAI | $2.00 | $5.00 | xAI's mid-tier |
| Grok-3 | xAI | $30.00 | $150.00 | Previous gen, same price as Grok-4 |
| Grok-3-mini | xAI | $3.00 | $5.00 | Budget reasoning |

*Sources: [OpenAI pricing](https://openai.com/api/pricing/), [Anthropic pricing](https://www.anthropic.com/pricing), [Google AI pricing](https://ai.google.dev/pricing), [xAI pricing](https://docs.x.ai/docs/models#models-and-pricing), [DeepSeek pricing](https://api-docs.deepseek.com/quick_start/pricing), [Together.ai](https://www.together.ai/pricing) for Llama 4 hosted inference. All checked February 2026.*

## What stands out

The 120x gap is real. GPT-5 mini at $0.25/M input vs Claude Opus 4 at $15/M input. 60x difference on input alone, 37x on output. For most production workloads, the mini-class models handle 80%+ of tasks just fine.

xAI is pricing itself out. Grok-4 at $30/$150 per million tokens is the most expensive API on the market. That's 2x Claude Opus and 17x GPT-5.2 on input. Unless you need something Grok does better (hard to name what that is), the pricing makes no sense for production use.

Google is quietly the cheapest. Gemini 2.0 Flash at $0.10/$0.40 matches GPT-4.1 nano and undercuts almost everything else. If your use case tolerates the quality tradeoff, it's the best deal available.

Open-weight models changed the math. Llama 4 Maverick at $0.27/$0.85 through hosted APIs is cheap, but the real story is self-hosting. Running Llama on your own GPUs drops the effective cost below $0.10/M tokens for input. The breakeven vs API depends on volume, but for companies doing 10B+ tokens/month, self-hosting wins.

## Beyond the price tag

The table is just the start. What actually matters:

Output tokens cost 3-8x more than input. This is consistent across every provider. If your app generates long responses (code, reports, content), output cost dominates your bill. Trim your outputs.

Caching changes everything. [OpenAI](https://platform.openai.com/docs/guides/prompt-caching) and [Anthropic](https://docs.anthropic.com/en/docs/build-with-claude/prompt-caching) both offer prompt caching that cuts repeat-context costs by 50-90%. If you're sending the same system prompt or few-shot examples on every call, caching alone might cut your bill in half.

Quality gaps are shrinking. A year ago, there was a clear hierarchy: GPT-4 > Claude 3 > everything else. Now GPT-5 mini, Claude Sonnet 4, and Gemini 2.5 Flash are all competitive for most tasks. The premium models (GPT-5.2, Opus 4) still win on complex reasoning and long-form analysis, but the gap keeps closing.

Latency matters more than price. The cheapest model that takes 8 seconds to respond might cost you more in user drop-off than a 2x pricier model that responds in 1.5 seconds. Benchmark latency alongside cost.

## Who should use what

High-volume production (chatbots, classification, extraction): GPT-5 mini or Gemini 2.0 Flash. Both under $0.50/M input with solid quality.

Code generation: Claude Sonnet 4 or GPT-5.2. Sonnet is generally better at following complex coding instructions. GPT-5.2 has an edge on multi-file refactoring.

Research and analysis: Claude Opus 4 if budget allows. GPT-5.2 if not. These tasks benefit most from the premium models.

Cost-sensitive startups: Llama 4 Maverick self-hosted, or GPT-4.1 nano for API. Get to market first, pick the right model later.

## What's next

Pricing has dropped roughly 10x per year for equivalent quality over the past three years. There's no reason to think that stops. By Q4 2026, expect GPT-5 mini-equivalent quality at $0.05/M input or less.

The real shift is happening at the infrastructure layer. Custom silicon (Google TPUs, Amazon Trainium, Microsoft Maia) is starting to undercut Nvidia GPU economics. As that scales, hosted API pricing will drop faster than self-hosting costs — potentially flipping the build-vs-buy calculation for mid-size companies.

We'll update this comparison monthly. [Subscribe to get updates](/#newsletter) when pricing changes.

---

*This analysis is part of Kael Research's ongoing coverage of AI market economics. We track pricing, adoption, and competition across the AI industry. [See our full research briefs](/briefs) for deeper analysis on specific markets.*
